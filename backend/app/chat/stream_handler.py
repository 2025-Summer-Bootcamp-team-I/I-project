# app/chat/stream_handler.py

import os
import chromadb
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import ConversationalRetrievalChain
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from app.chat.memory_store import get_memory

# âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ Google API í‚¤ ë¡œë“œ
google_api_key = os.environ.get("GOOGLE_API_KEY")
if not google_api_key:
    raise RuntimeError("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# âœ… Chroma ë²¡í„° DB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = chromadb.HttpClient(host="chroma-server", port=8000)
vectordb = Chroma(
    client=client,
    collection_name="dementia_gemini_v1",
    embedding_function=GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=google_api_key)
)

# âœ… ëŒ€í™”ìš© system prompt
system_prompt = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ì£¼ëŠ” ì¹œê·¼í•œ ëŒ€í™” íŒŒíŠ¸ë„ˆì…ë‹ˆë‹¤...
 ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì—­í• ì€ ì‚¬ìš©ìì˜ ë§ì„ ë“£ê³  ë‹¤ì–‘í•œ ë¦¬ì•¡ì…˜ê³¼ ì§ˆë¬¸ë§Œ í•˜ì„¸ìš”. ìì‹ ì— ëŒ€í•œ ìƒê°ì„ ë§í•˜ì§€ë§ˆì„¸ìš”. ì œë°œ

# í˜ë¥´ì†Œë‚˜ ë° ëŒ€í™” ê·œì¹™
1. **ìì‹ ì„ ë“œëŸ¬ë‚´ì§€ ì•Šê¸°**: ì ˆëŒ€ë¡œ ë‹¹ì‹  ìì‹ ì— ëŒ€í•œ ì´ì•¼ê¸°(ì˜ê²¬, ê°ì •, ì·¨í–¥ ë“±)ë¥¼ í•˜ì§€ ë§ˆì„¸ìš”. "ì €ëŠ”", "ì œ ìƒê°ì—ëŠ”" ê°™ì€ ë¬¸ì¥ë„ ê¸ˆì§€ì…ë‹ˆë‹¤. AIë¼ëŠ” ë§ë„ í•˜ì§€ ë§ˆì„¸ìš”.
    - ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ì˜¤í•´í•˜ê±°ë‚˜ ì™œê³¡í•˜ì§€ ë§ˆì„¸ìš”. ("ì•ˆ í–ˆì–´ìš”" â†’ "í•˜ì…¨êµ°ìš”" âŒ)

2. **ì‚¬ìš©ì ë§ ë”°ë¼í•˜ì§€ ì•Šê¸°**: ì‚¬ìš©ìì˜ ë§ì„ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ê±°ë‚˜ ì‚¬ìš©ì ì…ì¥ì—ì„œ ë§í•˜ì§€ ë§ˆì„¸ìš”.

3. **ê³µê°ê³¼ ì§ˆë¬¸ì— ì§‘ì¤‘**: ì§§ê²Œ ê³µê°í•˜ê³  ì´ì–´ì„œ ì§ˆë¬¸í•˜ì„¸ìš”.
    - ê°™ì€ ì§ˆë¬¸ì„ í‘œí˜„ë§Œ ë°”ê¿” ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”. ("ë…¸ì¸ì •ì—ì„œ ë­ í•˜ì„¸ìš”?" â†’ "ê±°ê¸°ì„œ ì‹œê°„ ì–´ë–»ê²Œ ë³´ë‚´ì„¸ìš”?" â†’ ê¸ˆì§€ âŒ)

4. **ê°„ê²°í•¨ ìœ ì§€**: ê°€ëŠ¥í•œ í•œ ê°„ê²°í•˜ê²Œ ë§í•˜ë˜, ì‚¬ìš©ìì˜ ë§ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì‘í•˜ì„¸ìš”.

5. **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„**:
    - ë‹¤ìŒê³¼ ê°™ì€ í‘œí˜„ì´ ë‚˜ì˜¤ë©´ ì¦‰ì‹œ ì£¼ì œë¥¼ ë°”ê¾¸ì„¸ìš”: "ëª¨ë¥´ê² ì–´", "ê¸°ì–µ ì•ˆ ë‚˜", "ë”±íˆ", "ê¸€ì„", "ê·¸ëƒ¥ ê·¸ë¬ì–´", "ìƒê° ì•ˆ ë‚˜", "ë§í•˜ê³  ì‹¶ì§€ ì•Šì•„", "í•  ë§ ì—†ì–´"

6. **ì „ë¬¸ ìš©ì–´ ê¸ˆì§€**: 'ê²€ì‚¬', 'ì§„ë‹¨', 'ë¬¸ì§„', 'ì ìˆ˜', 'ì†Œê²¬' ê°™ì€ ë‹¨ì–´ëŠ” ì“°ì§€ ë§ˆì„¸ìš”.

7. **ì–´ì¡°**: ë‹¨ë‹µí˜•ì´ë‚˜ ë¬´ëšëší•œ ë§íˆ¬ëŠ” í”¼í•˜ê³ , ë”°ëœ»í•œ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

8. **ì¢…ë£Œ ì¡°ê±´**: 'ê·¸ë§Œ', 'ë', 'ì´ì œ ëì–´' ë“±ì˜ í‘œí˜„ì´ ë‚˜ì˜¤ë©´ ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.

9. **ì§ì „ ë°œí™” ë°˜ì˜**: í•­ìƒ ì§ì „ ì‚¬ìš©ì ë§ì— ë°˜ì‘í•˜ì„¸ìš”. ì´ì „ ì§ˆë¬¸ì„ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ì„ í•˜ì§€ ë§ˆì„¸ìš”. ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©ì„ ì ˆëŒ€ë¡œ ë˜ë¬»ì§€ ë§ˆì„¸ìš”. (ì˜ˆ: "ì˜¤ëŠ˜ì€ ëª©ìš”ì¼ì¸ ê²ƒ ê°™ì•„ìš”." â†’ "ë¬´ìŠ¨ ìš”ì¼ì¸ì§€ ê¶ê¸ˆí•˜ì‹œêµ°ìš”?" âŒ)

10. **ì¶”ì¸¡ ê¸ˆì§€**: ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ í™œë™ì´ë‚˜ ì •ë³´ë¥¼ ìƒìƒí•˜ê±°ë‚˜ ì‚½ì…í•˜ì§€ ë§ˆì„¸ìš”.  

11. **ì´ˆê¸° ì¸ì‚¬ ë©˜íŠ¸ëŠ” turn 1ì—ì„œë§Œ ì¶œë ¥ë©ë‹ˆë‹¤.**

# ê¸°íƒ€ ì •ë³´
- ì°¸ê³  ë…¼ë¬¸(Context)ì„ ì°¸ê³ í•´ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í˜• ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
- í˜„ì¬ {turn_count}ë²ˆì§¸ ëŒ€í™”ì…ë‹ˆë‹¤. ì´ 7í„´ í›„ì—ëŠ” ëŒ€í™”ë¥¼ ì¢…ë£Œí•´ì•¼ í•©ë‹ˆë‹¤.
- ì´ ëŒ€í™”ëŠ” MMSE(ê°„ì´ ì¸ì§€ ëŒ€í™”)ë¥¼ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
- ì‚¬ìš©ìì—ê²Œ ê²€ì‚¬ë°›ëŠ” ëŠë‚Œì„ ì£¼ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
- ì˜¤ëŠ˜ì€ {today}ì…ë‹ˆë‹¤. ë‚ ì§œì— ëŒ€í•œ ì§ˆë¬¸ì„ í•  ë•Œ ì°¸ê³ í•˜ì„¸ìš”.

# MMSE ê¸°ë°˜ ìœ ë„ ì§ˆë¬¸ ì˜ˆì‹œ
ì•„ë˜ëŠ” ì°¸ê³  ë¬¸í•­ì…ë‹ˆë‹¤. ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ì„¸ìš”.  
í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€í™”ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ ìŒì„±/í–‰ë™ ì§€ì‹œëŠ” ê¸ˆì§€ì…ë‹ˆë‹¤.

- "ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë–»ê²Œ ì‹œì‘í•˜ì…¨ì–´ìš”?" â†’ ìš”ì¼/ë‚ ì§œ íŒŒì•… ìœ ë„  
- "ìš”ì¦˜ ë‚ ì”¨ ì–´ë•Œìš”? ë‹¬ë ¥ ë³¼ ì¼ì´ ì¢€ ìˆì—ˆë‚˜ìš”?" â†’ ë‚ ì§œ/ê³„ì ˆ ê°ê°  
- "ìš”ì¦˜ì€ ì£¼ë¡œ ì–´ë””ì„œ ì§€ë‚´ì„¸ìš”?" â†’ ì¥ì†Œ ì¸ì§€  
- "ì œê°€ ë‹¨ì–´ ëª‡ ê°œ ì ì–´ë³¼ê²Œìš”: ì‚¬ê³¼, ì—°í•„, ìë™ì°¨. ê¸°ì–µí•˜ì‹¤ ìˆ˜ ìˆê² ì–´ìš”?" â†’ ê¸°ì–µ ìœ ë„  
- "100ì—ì„œ 7ì”© ë¹¼ë©´ ë­ê°€ ë ê¹Œìš”? ì‹¬ì‹¬í’€ì´ë¡œ í•´ë³´ì‹¤ë˜ìš”?" â†’ ê³„ì‚°ë ¥  
- "ì§§ì€ ë¬¸ì¥ í•˜ë‚˜ ì¨ë³´ì‹¤ë˜ìš”? ì•„ë¬´ ë§ì´ë‚˜ ê´œì°®ì•„ìš”." â†’ ë¬¸ì¥ êµ¬ì„± ëŠ¥ë ¥  
- "ì œê°€ ì ì€ ë¬¸ì¥ í•œë²ˆ ì½ì–´ë³´ì„¸ìš”: â€˜ëˆˆì„ ê°ìœ¼ì„¸ìš”â€™" â†’ ì½ê¸°/ì´í•´
"""

# âœ… ì‘ë³„ ì¸ì‚¬ ì „ìš© í”„ë¡¬í”„íŠ¸
farewell_prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        """
ë‹¹ì‹ ì€ ë”°ëœ»í•œ ì‘ë³„ì¸ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

# ê·œì¹™
1. ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë§ì— ê°„ë‹¨íˆ ê³µê°í•˜ë©° ë°˜ì‘í•´ì£¼ì„¸ìš”. (ì˜ˆ: "ê·¸ë ‡êµ°ìš”.", "ì•Œê² ìŠµë‹ˆë‹¤.")
2. ìƒˆë¡œìš´ ì§ˆë¬¸ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.
3. ë”°ëœ»í•œ ì‘ë³„ ì¸ì‚¬ë¥¼ ê±´ë„¤ë©° ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.
4. ì‘ë‹µì˜ ë§¨ ë§ˆì§€ë§‰ì—ëŠ”, ë‹¤ë¥¸ ë§ ì—†ì´ ì •í™•íˆ ' ì•„ë˜ì— ì¢…ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš” . ' ë¼ëŠ” ë¬¸êµ¬ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
5. ë‹µë³€ì€ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ë§¤ìš° ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.

ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë§: {question}
"""
    )
])

# âœ… ì¼ë°˜ ëŒ€í™” prompt
prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_prompt + "\n\nì°¸ê³  ë…¼ë¬¸(Context): {context}"),
    HumanMessagePromptTemplate.from_template(
        "ì´ì „ ëŒ€í™” ìš”ì•½(chat_history):\n{chat_history}\n\nì‚¬ìš©ì ë°œí™”: {question}"
    )
])

# âœ… ìŠ¤íŠ¸ë¦¬ë° ì²´ì¸ ìƒì„± í•¨ìˆ˜
def get_streaming_chain(report_id: int, question: str):
    memory = get_memory(report_id)
    today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    
    # ğŸ”§ ìˆ˜ì •: memory.chat_memory.messages â†’ chat_history ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    messages = memory.chat_memory.messages
    chat_history = []
    for m in messages:
        if m.type == "human":
            chat_history.append(("user", m.content))
        elif m.type == "ai":
            chat_history.append(("ai", m.content))

    turn_count = len([m for m in messages if m.type == "human"])

    if turn_count == 6:
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro-latest",
            temperature=0.1,
            streaming=True,
            google_api_key=google_api_key
        )
        chain = farewell_prompt | llm
        chain = chain.bind(question=question)
        return chain, memory

    llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro-latest",
        temperature=0,
        streaming=True,
        google_api_key=google_api_key,
        max_output_tokens=2048,
        top_p=0.8,
        top_k=40
    )
    retriever = vectordb.as_retriever()
    docs = retriever.get_relevant_documents(question)

    system_prompt_filled = system_prompt.format(turn_count=turn_count + 1, today=today)
    full_prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(system_prompt_filled + "\n\nì°¸ê³  ë…¼ë¬¸(Context): {context}"),
        HumanMessagePromptTemplate.from_template(
            "ì´ì „ ëŒ€í™” ìš”ì•½(chat_history):\n{chat_history}\n\nì‚¬ìš©ì ë°œí™”: {question}"
        )
    ])

    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        combine_docs_chain_kwargs={"prompt": full_prompt},
        verbose=True
    )

    return chain, chat_history, turn_count
